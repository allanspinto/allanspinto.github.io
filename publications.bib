% Encoding: UTF-8

@InProceedings{Pinto2012SIBGRAPI,
  author    = {A. da Silva Pinto and H. Pedrini and W. Schwartz and A. Rocha},
  title     = {Video-Based Face Spoofing Detection through Visual Rhythm Analysis},
  booktitle = {25th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
  year      = {2012},
  pages     = {221-228},
  month     = aug,
  abstract  = {Recent advances on biometrics, information forensics, and security have improved the accuracy of biometric systems, mainly those based on facial information. However, an ever-growing challenge is the vulnerability of such systems to impostor attacks, in which users without access privileges try to authenticate themselves as valid users. In this work, we present a solution to video-based face spoofing to biometric systems. Such type of attack is characterized by presenting a video of a real user to the biometric system. To the best of our knowledge, this is the first attempt of dealing with video-based face spoofing based in the analysis of global information that is invariant to video content. Our approach takes advantage of noise signatures generated by the recaptured video to distinguish between fake and valid access. To capture the noise and obtain a compact representation, we use the Fourier spectrum followed by the computation of the visual rhythm and extraction of the gray-level co-occurrence matrices, used as feature descriptors. Results show the effectiveness of the proposed approach to distinguish between valid and fake users for video-based spoofing with near-perfect classification results.},
  doi       = {10.1109/SIBGRAPI.2012.38},
  issn      = {1530-1834},
  keywords  = {Biometrics, Face Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url       = {files/publications/2012-Pinto2012SIBGRAPI.pdf},
}

@InProceedings{Chingovska2013ICB,
  author    = {I. Chingovska and A. Pinto and H. Pedrini and W.S. Schwartz and A. Rocha and A. Anjos and S. Marcel \textit{et al.}},
  title     = {The 2nd competition on counter measures to 2D face spoofing attacks},
  booktitle = {International Conference on Biometrics (ICB)},
  year      = {2013},
  pages     = {1-6},
  month     = jun,
  abstract  = {As a crucial security problem, anti-spoofing in biometrics, and particularly for the face modality, has achieved great progress in the recent years. Still, new threats arrive inform of better, more realistic and more sophisticated spoofing attacks. The objective of the 2nd Competition on Counter Measures to 2D Face Spoofing Attacks is to challenge researchers to create counter measures effectively detecting a variety of attacks. The submitted propositions are evaluated on the Replay-Attack database and the achieved results are presented in this paper.},
  doi       = {10.1109/ICB.2013.6613026},
  keywords  = {Biometrics, Face Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url       = {files/publications/2013-Chingovska2013ICB.pdf},
}

@Article{Menotti2015TIFS,
  author   = {Menotti, D. and Chiachia, G. and Pinto, A. and Robson Schwartz, W. and Pedrini, H. and Xavier Falcao, A. and Rocha, A.},
  title    = {Deep Representations for Iris, Face, and Fingerprint Spoofing Detection},
  journal  = {IEEE Transactions on Information Forensics and Security (T-IFS)},
  year     = {2015},
  volume   = {10},
  number   = {4},
  pages    = {864-879},
  month    = apr,
  issn     = {1556-6013},
  abstract = {Biometrics systems have significantly improved person identification and authentication, playing an important role in personal, national, and global security. However, these systems might be deceived (or spoofed) and, despite the recent advances in spoofing detection, current solutions often rely on domain knowledge, specific biometric reading systems, and attack types. We assume a very limited knowledge about biometric spoofing at the sensor to derive outstanding spoofing detection systems for iris, face, and fingerprint modalities based on two deep learning approaches. The first approach consists of learning suitable convolutional network architectures for each domain, whereas the second approach focuses on learning the weights of the network via back propagation. We consider nine biometric spoofing benchmarks - each one containing real and fake samples of a given biometric modality and attack type - and learn deep representations for each benchmark by combining and contrasting the two learning approaches. This strategy not only provides better comprehension of how these approaches interplay, but also creates systems that exceed the best known results in eight out of the nine benchmarks. The results strongly indicate that spoofing detection systems based on convolutional networks can be robust to attacks already known and possibly adapted, with little effort, to image-based attacks that are yet to come.},
  doi      = {10.1109/TIFS.2015.2398817},
  keywords = {Biometrics, Face Recognition, Fingerprint Recognition, Iris Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url      = {files/publications/2015-Menotti2015TIFS.pdf},
}

@Article{Pinto2015TIFS,
  author   = {Pinto, A. and Robson Schwartz, W. and Pedrini, H. and de Rezende Rocha, A.},
  title    = {Using Visual Rhythms for Detecting Video-Based Facial Spoof Attacks},
  journal  = {IEEE Transactions on Information Forensics and Security (T-IFS)},
  year     = {2015},
  volume   = {10},
  number   = {5},
  pages    = {1025-1038},
  month    = may,
  issn     = {1556-6013},
  abstract = {Spoofing attacks or impersonation can be easily accomplished in a facial biometric system wherein users without access privileges attempt to authenticate themselves as valid users, in which an impostor needs only a photograph or a video with facial information of a legitimate user. Even with recent advances in biometrics, information forensics and security, vulnerability of facial biometric systems against spoofing attacks is still an open problem. Even though several methods have been proposed for photo-based spoofing attack detection, attacks performed with videos have been vastly overlooked, which hinders the use of the facial biometric systems in modern applications. In this paper, we present an algorithm for video-based spoofing attack detection through the analysis of global information which is invariant to content, since we discard video contents and analyze content-independent noise signatures present in the video related to the unique acquisition processes. Our approach takes advantage of noise signatures generated by the recaptured video to distinguish between fake and valid access videos. For that, we use the Fourier spectrum followed by the computation of video visual rhythms and the extraction of different characterization methods. For evaluation, we consider the novel unicamp video-attack database, which comprises 17 076 videos composed of real access and spoofing attack videos. In addition, we evaluate the proposed method using the replay-attack database, which contains photo-based and video-based face spoofing attacks.},
  doi      = {10.1109/TIFS.2015.2395139},
  keywords = {Biometrics, Face Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url      = {files/publications/2015-Pinto2015TIFS.pdf},
}

@Article{Pinto2015TIP,
  author   = {Pinto, A. and Pedrini, H. and Robson Schwartz, W. and Rocha, A.},
  title    = {Face Spoofing Detection Through Visual Codebooks of Spectral Temporal Cubes},
  journal  = {IEEE Transactions on Image Processing (T-IP)},
  year     = {2015},
  volume   = {24},
  number   = {12},
  pages    = {4726-4740},
  month    = dec,
  issn     = {1057-7149},
  abstract = {Despite important recent advances, the vulnerability of biometric systems to spoofing attacks is still an open problem. Spoof attacks occur when impostor users present synthetic biometric samples of a valid user to the biometric system seeking to deceive it. Considering the case of face biometrics, a spoofing attack consists in presenting a fake sample (e.g., photograph, digital video, or even a 3D mask) to the acquisition sensor with the facial information of a valid user. In this paper, we introduce a low cost and software-based method for detecting spoofing attempts in face recognition systems. Our hypothesis is that during acquisition, there will be inevitable artifacts left behind in the recaptured biometric samples allowing us to create a discriminative signature of the video generated by the biometric sensor. To characterize these artifacts, we extract time-spectral feature descriptors from the video, which can be understood as a low-level feature descriptor that gathers temporal and spectral information across the biometric sample and use the visual codebook concept to find mid-level feature descriptors computed from the low-level ones. Such descriptors are more robust for detecting several kinds of attacks than the low-level ones. The experimental results show the effectiveness of the proposed method for detecting different types of attacks in a variety of scenarios and data sets, including photos, videos, and 3D masks.},
  doi      = {10.1109/TIP.2015.2466088},
  keywords = {Biometrics, Face Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url      = {files/publications/2015-Pinto2015TIP.pdf},
}

@InProceedings{Pinto2017ICIP,
  author    = {A. Pinto and D. Moreira and A. Bharati and J. Brogan and K. Bowyer and P. Flynn and W. Scheirer and A. Rocha},
  title     = {Provenance filtering for multimedia phylogeny},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2017},
  pages     = {1502-1506},
  month     = sep,
  abstract  = {Departing from traditional digital forensics modeling, which seeks to analyze single objects in isolation, multimedia phylogeny analyzes the evolutionary processes that influence digital objects and collections over time. One of its integral pieces is provenance filtering, which consists of searching a potentially large pool of objects for the most related ones with respect to a given query, in terms of possible ancestors (donors or contributors) and descendants. In this paper, we propose a two-tiered provenance filtering approach to find all the potential images that might have contributed to the creation process of a given query q. In our solution, the first (coarse) tier aims to find the most likely "host" images - the major donor or background - contributing to a composite/doctored image. The search is then refined in the second tier, in which we search for more specific (potentially small) parts of the query that might have been extracted from other images and spliced into the query image. Experimental results with a dataset containing more than a million images show that the two-tiered solution underpinned by the context of the query is highly useful for solving this difficult task.},
  doi       = {10.1109/ICIP.2017.8296532},
  issn      = {2381-8549},
  keywords  = {Graph Theory, Image Filtering, Image Retrieval, Social Networking, Image Provenance Analysis, Digital Image Forensics, Multimedia Forensics, Image Phylogeny},
  url       = {files/publications/2017-Pinto2017ICIP.pdf},
}

@InProceedings{Brogan2017ICIP,
  author    = {J. Brogan and P. Bestagini and A. Bharati and A. Pinto and D. Moreira and K. Bowyer and P. Flynn and A. Rocha and W. Scheirer},
  title     = {Spotting the difference: Context retrieval and analysis for improved forgery detection and localization},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2017},
  pages     = {4078-4082},
  month     = sep,
  abstract  = {As image tampering becomes ever more sophisticated and commonplace, the need for image forensics algorithms that can accurately and quickly detect forgeries grows. In this paper, we revisit the ideas of image querying and retrieval to provide clues to better localize forgeries. We propose a method to perform large-scale image forensics on the order of one million images using the help of an image search algorithm and database to gather contextual clues as to where tampering may have taken place. In this vein, we introduce five new strongly invariant image comparison methods and test their effectiveness under heavy noise, rotation, and color space changes. Lastly, we show the effectiveness of these methods compared to passive image forensics using Nimble [1], a new, state-of-the-art dataset from the National Institute of Standards and Technology (NIST).},
  doi       = {10.1109/ICIP.2017.8297049},
  issn      = {2381-8549},
  keywords  = {Graph Theory, Image Filtering, Image Retrieval, Social Networking, Image Provenance Analysis, Digital Image Forensics, Multimedia Forensics, Image Phylogeny},
  url       = {files/publications/2017-Brogan2017ICIP.pdf},
}

@InProceedings{Bharati2017ICIP,
  author    = {A. Bharati and D. Moreira and A. Pinto and J. Brogan and K. Bowyer and P. Flynn and W. Scheirer and A. Rocha},
  title     = {U-Phylogeny: Undirected provenance graph construction in the wild},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2017},
  pages     = {1517-1521},
  month     = sep,
  abstract  = {Deriving relationships between images and tracing back their history of modifications are at the core of Multimedia Phylogeny solutions, which aim to combat misinformation through doctored visual media. Nonetheless, most recent image phylogeny solutions cannot properly address cases of forged composite images with multiple donors, an area known as multiple parenting phylogeny (MPP). This paper presents a preliminary undirected graph construction solution for MPP, without any strict assumptions. The algorithm is underpinned by robust image representative keypoints and different geometric consistency checks among matching regions in both images to provide regions of interest for direct comparison. The paper introduces a novel technique to geometrically filter the most promising matches as well as to aid in the shared region localization task. The strength of the approach is corroborated by experiments with real-world cases, with and without image distractors (unrelated cases).},
  doi       = {10.1109/ICIP.2017.8296535},
  issn      = {2381-8549},
  keywords  = {Graph Theory, Image Filtering, Image Retrieval, Social Networking, Image Provenance Analysis, Digital Image Forensics, Multimedia Forensics, Image Phylogeny},
  url       = {files/publications/2017-Bharati2017ICIP.pdf},
}

@InBook{Pinto2018CRCPress,
  chapter   = {Counteracting Presentation Attacks in Face Fingerprint and Iris Recognition},
  pages     = {49},
  title     = {Deep Learning in Biometrics},
  publisher = {CRC Press},
  year      = {2018},
  author    = {Allan Pinto and Helio Pedrini and Michael Krumdick and Benedict Becker and Adam Czajka and Kevin W. Bowyer and Anderson Rocha},
  month     = mar,
  isbn      = {9781351264990},
  abstract  = {This chapter explores data-driven approaches to presentation attack detection for three biometric modalities: face, iris, and fingerprint. The primary aim of this chapter is to show how pretrained deep neural networks can be used to build classifiers that can distinguish between authentic images of faces, irises, and fingerprints and their static imitations. The most important, publicly available benchmarks representing various attack types were used in a unified presentation attack detection framework in both same-dataset and cross-dataset experiments. The pretrained VGG neural networks, being the core of this solution, tuned independently for each modality and each dataset present almost perfect accuracy for all three biometric techniques. In turn, low-classification accuracies achieved in cross-dataset evaluations show that models based on deep neural networks are sensitive not only to features specific to biometric imitations, but also to dataset-specific properties of samples. Thus, such models can provide a rapid solution in scenarios in which properties of imitations can be predicted but appropriate feature engineering is difficult. However, these models will perform worse if the properties of imitations being detected are unknown. This chapter also includes a current literature review summarizing up-to-date data-driven solutions to face, iris and finger liveness detection.},
  comment   = {Vatsa, M. and Singh, R. and Majumdar, A.},
  keywords  = {Biometrics, Face Recognition, Fingerprint Recognition, Iris Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url       = {files/publications/2018-Pinto2018CRCPress.pdf},
}

@Article{Moreira2018TIP,
  author   = {D. {Moreira} and A. {Bharati} and J. {Brogan} and A. {Pinto} and M. {Parowski} and K. W. {Bowyer} and P. J. {Flynn} and A. {Rocha} and W. J. {Scheirer}},
  title    = {Image Provenance Analysis at Scale},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2018},
  volume   = {27},
  number   = {12},
  pages    = {6109-6123},
  month    = dec,
  issn     = {1941-0042},
  abstract = {Prior art has shown it is possible to estimate, through image processing and computer vision techniques, the types and parameters of transformations that have been applied to the content of individual images to obtain new images. Given a large corpus of images and a query image, an interesting further step is to retrieve the set of original images whose content is present in the query image, as well as the detailed sequences of transformations that yield the query image, given the original images. This is a problem that recently has received the name of image provenance analysis. In these times of public media manipulation (e.g., fake news and meme sharing), obtaining the history of image transformations is relevant for fact checking and authorship verification, among many other applications. This paper presents an end-to-end processing pipeline for image provenance analysis which works at real-world scale. It employs a cutting-edge image filtering solution that is custom-tailored for the problem at hand, as well as novel techniques for obtaining the provenance graph that expresses how the images, as nodes, are ancestrally connected. A comprehensive set of experiments for each stage of the pipeline is provided, comparing the proposed solution with the state-of-the-art results, employing previously published data sets. In addition, this paper introduces a new data set of real-world provenance cases from the social media site Reddit, along with baseline results.},
  doi      = {10.1109/TIP.2018.2865674},
  keywords = {Graph Theory, Image Filtering, Image Retrieval, Social Networking, Image Provenance Analysis, Digital Image Forensics, Multimedia Forensics, Image Phylogeny},
  url      = {files/publications/2018-Moreira2018TIP.pdf},
}

@Article{Kuehlkamp2019TIFS,
  author   = {A. {Kuehlkamp} and A. Pinto and A. {Rocha} and K. W. {Bowyer} and A. {Czajka}},
  title    = {Ensemble of Multi-View Learning Classifiers for Cross-Domain Iris Presentation Attack Detection},
  journal  = {IEEE Transactions on Information Forensics and Security},
  year     = {2019},
  volume   = {14},
  number   = {6},
  pages    = {1419-1431},
  month    = jun,
  issn     = {1556-6021},
  abstract = {The adoption of large-scale iris recognition systems around the world has brought to light the importance of detecting presentation attack images (textured contact lenses and printouts). This paper presents a new approach in iris presentation attack detection (PAD) by exploring combinations of convolutional neural networks (CNNs) and transformed input spaces through binarized statistical image features (BSIFs). Our method combines lightweight CNNs to classify multiple BSIF views of the input image. Following explorations on complementary input spaces leading to more discriminative features to detect presentation attacks, we also propose an algorithm to select the best (and most discriminative) predictors for the task at hand. An ensemble of predictors makes use of their expected individual performances to aggregate their results into a final prediction. Results show that this technique improves on the current state of the art in iris PAD, outperforming the winner of LivDet-Iris 2017 competition both for intra- and cross-dataset scenarios, and illustrating the very difficult nature of the cross-dataset scenario.},
  doi      = {10.1109/TIFS.2018.2878542},
  keywords = {Biometrics, Iris Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url      = {files/publications/2019-Kuehlkamp2019TIFS.pdf},
}

@Article{Pinto2020TIFS,
  author   = {A. {Pinto} and S. {Goldenstein} and A. {Ferreira} and T. {Carvalho} and H. {Pedrini} and A. {Rocha}},
  title    = {Leveraging Shape, Reflectance and Albedo From Shading for Face Presentation Attack Detection},
  journal  = {IEEE Transactions on Information Forensics and Security},
  year     = {2020},
  volume   = {15},
  pages    = {3347-3358},
  month    = apr,
  issn     = {1556-6021},
  abstract = {Presentation attack detection is a challenging problem that aims at exposing an impostor user seeking to deceive the authentication system. In facial biometrics systems, this kind of attack is performed using a photograph, video, or 3D mask containing the biometric information of a genuine identity. In this paper, we propose a novel approach to detecting face presentation attacks based on intrinsic properties of the scene such as albedo, depth, and reflectance properties of the facial surfaces, which were recovered through a shape-from-shading (SfS) algorithm. To extract meaningful patterns from the different maps obtained with the SfS algorithm, we designed a novel shallow CNN architecture for learning features useful to the presentation attack detection (PAD). We performed several experiments considering the intra- and inter-dataset evaluation protocols. The obtained results showed the effectiveness of the proposed method considering several types of photo- and video-based presentation attacks, and in the cross-sensor scenario, besides achieving competitive results  for the inter-dataset evaluation protocol.},
  doi      = {10.1109/TIFS.2020.2988168},
  keywords = {Biometrics, Face Recognition, Presentation Attack Detection, Information Security, Digital Image Forensics},
  url      = {files/publications/2020-Pinto2020TIFS.pdf},
}

@InBook{Carvalho2012ERI,
  chapter   = {Crime Scene Investigation (CSI): da Fic\c{c}\~{a}o \`{a} Realidade},
  pages     = {1-23},
  title     = {VII Escola Regional de Inform\'{a}tica de Minas Gerais},
  publisher = {Anais da VII Escola Regional de InformÃ¡tica de Minas Gerais. 1ed.Juiz de Fora:},
  year      = {2012},
  author    = {Tiago Carvalho and A. Pinto and E. Silva and F. O. Costa and G. R. Pinheiro and A.Rocha},
  abstract  = {An astonishing number of digital documents, such as digital pictures, videos, text files, etc., are daily produced and broadcasted. However, their authenticity is usually a doubtful question, since tampering digital documents have been become a simple task through using existent manipulation tools. So, our trust on digital documents is constantly decreasing, making necessary to develop effective approaches to recover this trust. All these facts highlight the importance of digital forensics in our day-by-day life. Based on this, our work presents a forensics computing overview showing main kind of forensics problems and most recently approaches to treat them.},
  keywords  = {Digital Image Forensics, Multimedia Forensics, Information Security},
  url       = {files/publications/2012-Carvalho2012ERI.pdf},
}

@Article{Almeida2020IJPAS,
  author    = {Alexandre G. Almeida and Murilo Merlin and Allan Pinto and Ricardo da S. Torres and Sergio A. Cunha},
  title     = {Performance-level indicators of male elite handball teams},
  journal   = {International Journal of Performance Analysis in Sport},
  year      = {2020},
  volume    = {20},
  number    = {1},
  pages     = {1-9},
  month     = nov,
  abstract  = {The aim of this study was to identify the most relevant variables to characterise the performance level of the teams through Men's World Championships (2007-2019). Forty-seven attributes from match-related statistics and characteristics of players were analysed in 168 participant teams. Descriptive discriminant analysis classified correctly 69.6\% of the cases and selected the height of players, 9-m efficiency, international matches disputed, wing efficiency, blocked shots, 7-m goalkeeper efficiency and 2-min suspensions which were the most relevant indicators. Top-Elite was significantly different (one-way ANOVA) from Middle- and Low-Elite in all variables selected, except for 7-m goalkeeper efficiency. Linear regression shows that wing efficiency and blocked shots were the only variables with a tendency of changes through seven editions. The best teams have the tallest players and with more international matches disputed, were most efficient in 9-m and wing finalisations and block more shots in defence. These findings may guide scientists and sports trainers to select players, prescribe training procedures, analyse opponents and establish match strategies with special attention to these variables.},
  doi       = {10.1080/24748668.2019.1694305},
  eprint    = {https://doi.org/10.1080/24748668.2019.1694305},
  keywords  = {Sports Sciences, Performance Analysis},
  publisher = {Routledge},
  url       = {files/publications/2020-Almeida2020IJPAS.pdf},
}

@InBook{Pereira2020Springer,
  pages     = {289--311},
  title     = {The Rise of Data-Driven Models in Presentation Attack Detection},
  publisher = {Springer International Publishing},
  year      = {2020},
  author    = {Pereira, Luis A. M. and Allan Pinto and Andal{\'o}, Fernanda A. and Ferreira, Alexandre M. and Lavi, Bahram and Soriano-Vargas, Aurea and Cirne, Marcos V. M. and Rocha, Anderson},
  address   = {Cham},
  month     = jan,
  isbn      = {978-3-030-32583-1},
  abstract  = {Biometric systems are prevalent in access control but are vulnerable to frauds. A typical attempt of violating them is through presentation attacks, in which synthetic data is directly presented to an acquisition sensor to deceive these systems. A well-designed biometric system should have a presentation attack detection (PAD) module. A fruitful way to perform PAD is to model properties of peculiar traits (artifacts) in synthetic data. Studies have been advocating for approaches that seek to model the artifacts automatically from data (data-driven), achieving state-of-the-art results in PAD. However, the following questions arise from this literature: Which approaches are the state of the art? When do these approaches fail? How can such approaches complement the proposed ones based on human knowledge on PAD? How robust are these approaches under cross-dataset scenarios? Are these approaches robust against new attack types (e.g., face morphing)? Do these methods provide other ways to perform PAD, for example, using open-set classifiers rather than the classical binary formulation? Are these methods applicable to the multi-biometric setting? In this chapter, we address these questions through a literature review, focusing on three biometric modalities: face, fingerprint, and iris.},
  booktitle = {Deep Biometrics},
  comment   = {Jiang, Richard and Li, Chang-Tsun and Crookes, Danny and Meng, Weizhi and Rosenberger, Christophe},
  doi       = {10.1007/978-3-030-32583-1_13},
  keywords  = {Biometrics, Face Recognition, Fingerprint Recognition, Iris Recognition, Information Security, Digital Image Forensics},
  url       = {files/publications/2020-Pereira2020Springer.pdf},
}

@Article{Dias2020JSTARS,
  author   = {D. {Dias} and A. {Pinto} and U. {Dias} and R. {Lamparelli} and G. {Le Maire} and R. d. S. {Torres}},
  title    = {A Multirepresentational Fusion of Time Series for Pixelwise Classification},
  journal  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year     = {2020},
  volume   = {13},
  number   = {1},
  pages    = {4399-4409},
  month    = jul,
  issn     = {2151-1535},
  abstract = {This article addresses the pixelwise classification problem based on temporal profiles, which are encoded in 2-D representations based on recurrence plots, Gramian angular/ difference fields, and Markov transition field. We propose a multirepresentational fusion scheme that exploits the complementary view provided by those time series representations and different data-driven feature extractors and classifiers. We validate our ensemble scheme in the problem related to the classification of eucalyptus plantations in remote sensing images. Achieved results demonstrate that our proposal overcomes recently proposed baselines, and now represents the new state-of-the-art classification solution for the target dataset.},
  doi      = {10.1109/JSTARS.2020.3012117},
  keywords = {Remote Sensing, Machine Learning, Fusion Information},
  url      = {files/publications/2020-Dias2020JSTARS.pdf},
}

@InProceedings{Cordova2019ICMLA,
  author    = {M. A. {C{\'{o}}rdova} and L. G. L. {Decker} and J. L. {Flores-Campana} and A. A. {dos Santos} and J. S. {Concei{\c{c}}{\~{a}}o} and A. {Pinto} and H. {Pedrini} and R. {da S. Torres}},
  title     = {Pelee-Text: A Tiny Convolutional Neural Network for Multi-oriented Scene Text Detection},
  booktitle = {2019 18th IEEE International Conference On Machine Learning And Applications ( ICMLA)},
  year      = {2019},
  pages     = {400-405},
  month     = dec,
  abstract  = {Nowadays, scene text detection has received a lot of attention due to its complexity given variations in terms of orientations, font size, aspect ratio, and natural backgrounds. In this vein, several deep neural networks have been proposed to deal with this challenging problem. However, such networks produce "heavy" models, hampering their use in applications running in devices with computational constraints. Additionally, few works are focused on the detection of multi-oriented and/or multi-lingual text. Herein, we propose an end-to-end tiny convolutional neural network for multi-oriented multi-lingual scene text called Pelee- Text. Experimental results show that Pelee-Text is at least 3 times smaller than its counterparts with a speed of 2.93 and 18.64 frames per second for its multi-scale and 768-scale versions, respectively. Moreover, in terms of F-measure, our method achieved competitive results on four well-known datasets, i.e., ICDAR'2011 (90.96%), ICDAR'2013 (85.24%), ICDAR'2015 (80.08%), and MSRA-TD500 (80.90%).},
  doi       = {10.1109/ICMLA.2019.00075},
  keywords  = {Text Localization, Text Recognition, Machine Learning, Computer Vision, Mobile Devices},
  url       = {files/publications/2019-Cordova2019ICMLA.pdf},
}

@InProceedings{Decker2020VISAPP,
  author       = {Luis Gustavo Lorgus Decker. and Allan Pinto. and Jose Luis Flores Campana. and Manuel C{\'{o}}rdova Neira. and Andreza A. dos Santos. and Jhonatas S. Concei{\c{c}}{\~{a}}o. and Marcus A. Angeloni. and Lin Tzy Li. and Ricardo da S. Torres.},
  title        = {MobText: A Compact Method for Scene Text Localization},
  booktitle    = {Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 5: VISAPP,},
  year         = {2020},
  pages        = {343-350},
  organization = {INSTICC},
  publisher    = {SciTePress},
  abstract     = {Multiple research initiatives have been reported to yield highly effective results for the text detection problem. However, most of those solutions are very costly, which hamper their use in several applications that rely on the use of devices with restrictive processing power, like smartwatches and mobile phones. In this paper, we address this issue by investigating the use of efficient object detection networks for this problem. We propose the combination of two light architectures, MobileNetV2 and Single Shot Detector (SSD), for the text detection problem. Experimental results in the ICDAR'11 and ICDAR'13 datasets demonstrate that our solution yields the best trade-off between effectiveness and efficiency and also achieved the state-of-the-art results in the ICDAR'11 dataset with an f-measure of 96.09%.},
  doi          = {10.5220/0008954103430350},
  isbn         = {978-989-758-402-2},
  keywords     = {Text Localization, Text Recognition, Machine Learning, Computer Vision, Mobile Devices},
  url          = {files/publications/2020-Decker2020VISAPP.pdf},
}

@Article{Campana2020IEEEAccess,
  author   = {J. L. {Flores Campana} and A. {Pinto} and M. {Alberto C{\'{o}}rdova Neira} and L. {Gustavo Lorgus Decker} and A. {Santos} and J. S. {Concei{\c{c}}{\~{a}}o} and R. {da Silva Torres}},
  title    = {On the Fusion of Text Detection Results: A Genetic Programming Approach},
  journal  = {IEEE Access},
  year     = {2020},
  volume   = {8},
  number   = {1},
  pages    = {81257-81270},
  month    = apr,
  issn     = {2169-3536},
  abstract = {Hundreds of text detection methods have been proposed, motivated by their widespread use in several applications. Despite the huge progress in the area, which includes even the use of sophisticated learning schemes, ad-hoc post-processing procedures are often employed to improve the text detection rate, by removing both false positives and negatives. Another issue refers to the lack of the use of the complementary views provided by different text detection methods. This paper aims to fill these gaps. We propose the use of a soft computing framework, based on genetic programming (GP), to guide the definition of suitable post-processing procedures through the combination of basic operators, which may be applied to improve detection results provided by multiple methods at the same time. Performed experiments in the widely used ICDAR 2011, ICDAR 2013, and ICDAR 2015 datasets demonstrate that our GP-based approach leads to F1 effectiveness gains up to 5.1 percentage points, when compared to several baselines.},
  doi      = {10.1109/ACCESS.2020.2987869},
  keywords = {Text Localization, Text Recognition, Machine Learning, Computer Vision, Mobile Devices},
  url      = {files/publications/2020-Campana2020IEEEAccess.pdf},
}

@InProceedings{Conceicao2019SIBGRAPI,
  author    = {Jhonatas Concei{\c{c}}{\~{a}}o and Allan Pinto and Luis Decker and Jose Luis Campana and Manuel Neira and Andrezza dos Santos and Helio Pedrini and Ricardo Torres},
  title     = {Multi-Lingual Text Localization via Language-Specific Convolutional Neural Networks},
  booktitle = {Anais Estendidos da XXXII Conference on Graphics, Patterns and Images},
  year      = {2019},
  pages     = {215--218},
  address   = {Porto Alegre, RS, Brasil},
  month     = aug,
  publisher = {SBC},
  abstract  = {LocalizaÃ§Ã£o e Reconhecimento de texto em cena Ã© um tÃ³pico em visÃ£o computacional que objetiva delimitar regiÃµes candidatas em uma imagem de entrada contendo texto em cena. O desafio desta pesquisa consiste em desenvolver detectores capazes de lidar com diversas fontes de variabilidade tais como tamanho de fontes e cor, fundo complexo, texto em diferentes linguagens, entre outros. Este trabalho apresenta uma comparaÃ§Ã£o entre estratÃ©gias para a construÃ§Ã£o de modelos de classificaÃ§Ã£o baseados em Redes Neurais Convolucionais, para detectar elementos textuais em mÃºltiplas linguagens em imagens, tais como: (i) modelo de classificaÃ§Ã£o construÃ­do em um cenÃ¡rio multilÃ­ngue; e (ii) modelo de classificaÃ§Ã£o construÃ­do em um cenÃ¡rio de linguagem especÃ­fica. Os experimentos conduzidos neste trabalho indicam que modelos de linguagem especÃ­fica superam os modelos treinados em um cenÃ¡rio multilÃ­ngue, apresentando uma melhoria de 14.79%, 8.94%, e 11.43%, em termos de precisÃ£o, revocaÃ§Ã£o e f-measure, respectivamente.},
  doi       = {10.5753/sibgrapi.est.2019.8333},
  issn      = {2177-9384},
  keywords  = {Text Localization, Text Recognition, Machine Learning, Computer Vision, Mobile Devices},
  location  = {Rio de Janeiro},
  url       = {files/publications/2019-Conceicao2019SIBGRAPI.pdf},
}

@PhdThesis{Pinto2018PhDThesis,
  author   = {Allan Pinto},
  title    = {Analysis of intrinsic and extrinsic properties of biometric samples for presentation attack detection},
  school   = {Institute of Computing, University of Campinas},
  year     = {2018},
  type     = {{Ph.D. thesis}},
  address  = {Brazil},
  month    = sep,
  abstract = {Recent advances in biometrics, information forensics, and security have improved the recognition effectiveness of biometric systems. However, an ever-growing challenge is the vulnerability of such systems against presentation attacks, in which impostor users create synthetic samples from the original biometric information of a legitimate user and show them to the acquisition sensor seeking to authenticate themselves as legitimate users. Depending on the trait used by the biometric authentication, the attack types vary with the type of material used to build the synthetic samples. For instance, in facial biometric systems, an attempted attack is characterized by the type of material the impostor uses such as a photograph, a digital video, or a 3D mask with the facial information of a target user. In iris-based biometrics, presentation attacks can be accomplished with printout photographs or with contact lenses containing the iris patterns of a target user or even synthetic texture patterns. In fingerprint biometric systems, impostor users can deceive the authentication process using replicas of the fingerprint patterns built with synthetic materials such as latex, play-doh, silicone, among others. This research aimed at developing presentation attack detection (PAD) solutions whose objective is to detect attempted attacks considering different attack types, in each modality. The lines of investigation presented in this thesis aimed at devising and developing representations based on spatial, temporal and spectral information from noise signature, intrinsic properties of the biometric data (e.g., albedo, reflectance, and depth maps), and supervised feature learning techniques, taking into account different testing scenarios including cross-sensor, intra-, and inter-dataset scenarios. The main findings and contributions presented in this thesis include: the creation of a large and publicly available benchmark containing 17K videos of presentation attacks and bona-fide presentations simulations in a facial biometric system, whose collect were formally authorized by the Research Ethics Committee at Unicamp; the development of novel approaches to modeling and analysis of extrinsic properties of biometric samples related to artifacts added during the manufacturing of the synthetic samples and their capture by the acquisition sensor, whose results were superior to several approaches published in the literature that use traditional methods for image analysis (e.g., texture-based analysis); the investigation of an approach based on the analysis of intrinsic properties of faces, estimated from the information of shadows present on their surface; and the investigation of different approaches to automatically learning representations related to our problem, whose results were superior or competitive to state-of-the-art methods for the biometric modalities considered in this thesis. We also considered in this research the design of efficient neural networks with shallow architectures capable of learning characteristics related to our problem from small sets of data available to develop and evaluate PAD solutions.},
  keywords = {Biometrics, Face Recognition, Fingerprint Recognition, Iris Recognition, Information Security, Digital Image Forensics},
  url      = {files/publications/2018-Pinto2018PhDThesis.pdf},
}

@Article{Silva2020Sensors,
  author    = {Silva, Ewerton and da S Torres, Ricardo and Pinto, Allan and Tzy Li, Lin and S Vianna, Jos{\'e} Eduardo and Azevedo, Rodolfo and Goldenstein, Siome},
  title     = {Application-oriented retinal image models for computer vision},
  journal   = {Sensors},
  year      = {2020},
  volume    = {20},
  number    = {13},
  pages     = {3746},
  month     = jul,
  abstract  = {Energy and storage restrictions are relevant variables that software applications should be concerned about when running in low-power environments. In particular, computer vision (CV) applications exemplify well that concern, since conventional uniform image sensors typically capture large amounts of data to be further handled by the appropriate CV algorithms. Moreover, much of the acquired data are often redundant and outside of the application's interest, which leads to unnecessary processing and energy spending. In the literature, techniques for sensing and re-sampling images in non-uniform fashions have emerged to cope with these problems. In this study, we propose Application-Oriented Retinal Image Models that define a space-variant configuration of uniform images and contemplate requirements of energy consumption and storage footprints for CV applications. We hypothesize that our models might decrease energy consumption in CV tasks. Moreover, we show how to create the models and validate their use in a face detection/recognition application, evidencing the compromise between storage, energy, and accuracy.},
  doi       = {10.3390/s20133746},
  keywords  = {Retinal Image Model, Computer Vision, Energy Consumption, Image Processing},
  publisher = {Multidisciplinary Digital Publishing Institute},
  url       = {files/publications/2020-Silva2020Sensors.pdf},
}

@InProceedings{Pinto2009SIICUSP,
  author    = {Allan da Silva Pinto and Jorge Luiz e Silva},
  title     = {ChipCflow - Uma Ferramenta para execu{\c{c}}{\~{a}}o de Algoritmos Utilizando o Modelo a Fluxo de Dados Din{\^{a}}mico em Hardware Reconfigur{\'{a}}vel-Circuito Matching e Instancias},
  booktitle = {Simp{\'{o}}sio Internacional de Inicia{\c{c}}{\~{a}}o Cient{\'{i}}fica da USP (SIICUSP)},
  year      = {2009},
  keywords  = {Dataflow Architecture, FPGA, VHDL, Reconfigurable Computing},
  url       = {files/publications/2009-Pinto2009SIICUSP.pdf},
}

@MastersThesis{Pinto2013MasterDissertation,
  author   = {Allan Pinto},
  title    = {A countermeasure method for video-based face spoofing attacks},
  school   = {Institute of Computing, University of Campinas},
  year     = {2013},
  address  = {Brazil},
  month    = oct,
  keywords = {Biometrics, Face Recognition, Fingerprint Recognition, Iris Recognition, Information Security, Digital Image Forensics},
  url      = {files/publications/2013-Pinto2013MasterDissertation.pdf},
}

@InProceedings{Pinto2020ICIP,
  author    = {A. {Pinto} and M. A. {C{\'o}rdova} and L. G. L. {Decker} and J. L. {Flores-Campana} and M. R. {Souza} and A. A. {dos Santos} and J. S. {Concei{\c{c}}{\~{a}}o} and H. F. {Gagliardi} and D. C. {Luvizon} and R. d. S. {Torres} and H. {Pedrini}},
  title     = {Parallax Motion Effect Generation Through Instance Segmentation And Depth Estimation},
  booktitle = {2020 IEEE International Conference on Image Processing (ICIP)},
  year      = {2020},
  pages     = {1621-1625},
  month     = oct,
  abstract  = {Stereo vision is a growing topic in computer vision due to the innumerable opportunities and applications this technology offers for the development of modern solutions, such as virtual and augmented reality applications. To enhance the user's experience in three-dimensional virtual environments, the motion parallax estimation is a promising technique to achieve this objective. In this paper, we propose an algorithm for generating parallax motion effects from a single image, taking advantage of state-of-the-art instance segmentation and depth estimation approaches. This work also presents a comparison against such algorithms to investigate the trade-off between efficiency and quality of the parallax motion effects, taking into consideration a multi-task learning network capable of estimating instance segmentation and depth estimation at once. Experimental results and visual quality assessment indicate that the PyD-Net network (depth estimation) combined with Mask R-CNN or FBNet networks (instance segmentation) can produce parallax motion effects with good visual quality.},
  keywords  = {Computer Vision, Machine Learning, Segmentation, Object Detection},
  url       = {files/publications/2020-Pinto2020ICIP.pdf},
}

@Article{Cordova2020IEEEAccess,
  author   = {M. {C{\'o}rdova} and A. {Pinto} and H. {Pedrini} and R. d. S. {Torres}},
  title    = {Pelee-Text++: A Tiny Neural Network for Scene Text Detection},
  journal  = {IEEE Access},
  year     = {2020},
  volume   = {8},
  number   = {1},
  pages    = {223172-223188},
  month    = dec,
  issn     = {2169-3536},
  abstract = {Scene text detection has become an important field in the computer vision area due to the increasing number of applications. This is a very challenging problem as textual elements are commonly found in “noisy” and complex natural scenes. Another issue refers to the presence of texts encoded into different languages within the same image. State-of-the-art solutions rely on the use of deep neural network approaches or even ensembles of them. However, such solutions are associated with “heavy” models, which are computationally expensive in terms of memory and storage footprints, which hampers their use in real-time mobile applications. In this work, we introduce Pelee-Text++, a lightweight neural network architecture for multi-lingual multi-oriented scene text detection, especially tailored to running on devices with computational restrictions. Additionally, to the best of our knowledge, this is the first work to evaluate the performance of text detection methods in commercial smartphones. Over this scenario, Pelee-Text++ processes 2.94 frames per second and it is the only evaluated approach that did not cause memory issues on smartphones, even using an input image of  $1024\times 1024$  pixels. Our proposal achieves a promising trade-off between efficiency and effectiveness, with a model size of 27 Megabytes and F-measure of 91.20%, 85.78%, 81.72%, 80.30%, 82.53% and 66.51% on ICDAR 2011, ICDAR 2013, ICDAR 2015, MSRA-TD500, ReCTS 2019 and Multi-lingual 2019 datasets, respectively.},
  doi      = {10.1109/ACCESS.2020.3043813},
  keywords = {Performance evaluation;Training;Computational modeling;Neural networks;Random access memory;Proposals;Smart phones;Text detection;mobile-network;mobile devices;multi-oriented text;multi-lingual;convolutional neural network},
  url      = {https://doi.org/10.1109/ACCESS.2020.3043813},
}

@Article{Cirino2021SRNature,
  author    = {Cirino, Carolina and Gobatto, Claudio A. and Pinto, Allan S. and Torres, Ricardo S. and Hartz, Charlini S. and Azevedo, Paulo H. S. M. and Moreno, Marlene A. and Manchado-Gobatto, F{\'u}lvia B.},
  title     = {Complex network model indicates a positive effect of inspiratory muscles pre-activation on performance parameters in a judo match},
  journal   = {Scientific Reports},
  year      = {2021},
  volume    = {11},
  number    = {1},
  pages     = {11148},
  month     = may,
  issn      = {2045-2322},
  abstract  = {This study investigated the effects of inspiratory muscle pre-activation (IMPA) on the interactions among the technical-tactical, physical, physiological, and psychophysiological parameters in a simulated judo match, based on the centrality metrics by complex network model. Ten male athletes performed 4 experimental sessions. Firstly, anthropometric measurements, maximal inspiratory pressure (MIP) and global strenght of the inspiratory muscles  were determined. In the following days, all athletes performed four-minute video-recorded judo matches, under three conditions: without IMPA (CON), after IMPA at 15{\%} (IMPA15), and at 40{\%} (IMPA40) of MIP using an exerciser device. Blood lactate, heart rate and rating of perceived exertion were monitored, and the technical-tactical parameters during the match were related to offensive actions and the time-motion. Based on the complex network, graphs were constructed for each scenario (CON, IMPA15, and IMPA40) to investigate the Degree and Pagerank centrality metrics. IMPA40 increased the connectivity of the physical and technical-tactical parameters in complex network and highlighted the combat frequency and average combat time in top-five ranked nodes. IMPA15 also favoured the interactions among the psychophysiological, physical, and physiological parameters. Our results suggest the positive effects of the IMPA, indicating this strategy to prepare the organism (IMPA15) and to improve performance (IMPA40) in judo match.},
  day       = {27},
  doi       = {10.1038/s41598-021-90394-1},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Springer Science and Business Media LLC},
  url       = {https://doi.org/10.1038/s41598-021-90394-1},
}

@Article{Segundo2021JSTARS,
  author    = {Pamplona Segundo, Mauricio and Pinto, Allan and Minetto, Rodrigo and Torres, Ricardo da S. and Sarkar, Sudeep},
  title     = {Measuring economic activity from space: a case study using flying airplanes and COVID-19},
  journal   = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year      = {2021},
  volume    = {14},
  pages     = {1-1},
  issn      = {2151-1535},
  abstract  = {This work introduces a novel solution to measure economic activity through remote sensing for a wide range of spatial areas. We hypothesize that disturbances in human behavior caused by major life-changing events leave signatures in satellite imagery that allows devising relevant image-based indicators to estimate their impacts and support decision-makers. We present a case study for the COVID-19 coronavirus outbreak, which imposed severe mobility restrictions and caused worldwide disruptions, using flying airplane detection around the 30 busiest airports in Europe to quantify and analyze the lockdown's effects and post-lockdown recovery. Our solution won the Rapid Action Coronavirus Earth observation (RACE) upscaling challenge, sponsored by the European Space Agency and the European Commission, and now is integrated into the RACE dashboard. This platform combines satellite data and artificial intelligence to promote a progressive and safe reopening of essential activities. Code, trained model, and data are available at https://github.com/maups/covid19-custom-script-contest},
  doi       = {10.1109/JSTARS.2021.3094053},
  keywords  = {Machine Learning, Artificial Intelligence, Remote Sensing},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Leal2022HM,
  author    = {Leal, Kleber and Pinto, Allan and Torres, Ricardo and Elferink-Gemser, Marije and Cunha, Sergio},
  title     = {Characterization and analyses of dribbling actions in soccer: a novel definition and effectiveness of dribbles in the 2018 FIFA World Cup RussiaTM},
  journal   = {Human Movement},
  year      = {2022},
  volume    = {23},
  number    = {1},
  pages     = {10--17},
  issn      = {1899-1955},
  abstract  = {Dribbling is a meaningful skill in soccer, due to its effectiveness to create opportunities for scoring. Several studies analyzed dribbling actions from different perspectives, including among others, the development of talented players. Despite recent progresses, however, there is still no consensus about the definition of dribbling. This study proposes a more comprehensive definition than earlier applied, considering the key elements present in other proposals found in the literature. This study aims to validate the proposed definition considering evaluations with three experts working with events from the 2018 FIFA World Cup Russia{\texttrademark} contest and also to apply the proposed definition in the analysis of the effectiveness of dribbling actions performed by elite players when playing for their respective national teams. We designed a protocol to collect the opinion from experts regarding the classification of events as dribble or non-dribble. To evaluate the quality of experts' opinions working with the novel dribbling definition, we computed the accuracy and precision, and Krippendorff's alpha coefficient to measure the agreement between them. On average, the accuracy and precision values reach $96.25\pm4.51\%$, and $97.08\pm1.91\%$ and an agreement rate of $0.93$. The obtained results indicate that our definition of dribbling was clear and easily understood by the experts, which suggests that it could be useful to support soccer scouting of dribbling actions. Furthermore, the agreement value showed a near-perfect consensus between experts. We also analysed the effectiveness of dribbling actions considering the number of dribbles per 90 minutes played and success rate distributions for different national teams and their respective players that participated of the 2018 FIFA World Cup Russia{\texttrademark}.},
  doi       = {10.5114/hm.2021.104182},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Termedia Sp. z.o.o.},
  url       = {http://dx.doi.org/10.5114/hm.2021.104182},
}

@Article{Junior2021MTAP,
  author    = {Barbon Junior, Sylvio and Pinto, Allan and Barroso, Jo{\~a}o Vitor and Caetano, Fabio Giuliano and Moura, Felipe Arruda and Cunha, Sergio Augusto and Torres, Ricardo da Silva},
  title     = {Sport action mining: Dribbling recognition in soccer},
  journal   = {Multimedia Tools and Applications},
  year      = {2021},
  volume    = {81},
  number    = {3},
  pages     = {4341--4364},
  month     = dec,
  issn      = {1573-7721},
  abstract  = {Recent advances in Computer Vision and Machine Learning empowered the use of image and positional data in several high-level analyses in Sports Science, such as player action classification, recognition of complex human movements, and tactical analysis of team sports. In the context of sports action analysis, the use of positional data allows new developments and opportunities by taking into account players' positions over time. Exploiting the positional data and its sequence in a systematic way, we proposed a framework that bridges association rule mining and action recognition. The proposed Sports Action Mining (SAM) framework is grounded on the usage of positional data for recognising actions, e.g., dribbling. We hypothesise that different sports actions could be modelled using a sequence of confidence levels computed from previous players' locations. The proposed method takes advantage of an association rule mining algorithm (e.g., FPGrowth) to generate displacement sequences for modelling actions in soccer. In this context, transactions are sequences of traces representing player displacements, while itemsets are players' coordinates on the pitch. The experimental results pointed out the Random Forest classifier achieved a balanced accuracy value of 93.3{\%} for detecting dribbling actions, which are considered complex events in soccer. Additionally, the proposed framework provides insights on players' skills and player's roles based on a small amount of positional data.},
  day       = {07},
  doi       = {10.1007/s11042-021-11784-1},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Springer Science and Business Media LLC},
  url       = {https://doi.org/10.1007/s11042-021-11784-1},
}

@Article{Cordova2022Sensors,
  author         = {Córdova, Manuel and Pinto, Allan and Hellevik, Christina Carrozzo and Alaliyat, Saleh Abdel-Afou and Hameed, Ibrahim A. and Pedrini, Helio and Torres, Ricardo da S.},
  title          = {Litter Detection with Deep Learning: A Comparative Study},
  journal        = {Sensors},
  year           = {2022},
  volume         = {22},
  number         = {2},
  pages          = {548},
  month          = jan,
  issn           = {1424-8220},
  abstract       = {Pollution in the form of litter in the natural environment is one of the great challenges of our times. Automated litter detection can help assess waste occurrences in the environment. Different machine learning solutions have been explored to develop litter detection tools, thereby supporting research, citizen science, and volunteer clean-up initiatives. However, to the best of our knowledge, no work has investigated the performance of state-of-the-art deep learning object detection approaches in the context of litter detection. In particular, no studies have focused on the assessment of those methods aiming their use in devices with low processing capabilities, e.g., mobile phones, typically employed in citizen science activities. In this paper, we fill this literature gap. We performed a comparative study involving state-of-the-art CNN architectures (e.g., Faster RCNN, Mask-RCNN, EfficientDet, RetinaNet and YOLO-v5), two litter image datasets and a smartphone. We also introduce a new dataset for litter detection, named PlastOPol, composed of 2418 images and 5300 annotations. The experimental results demonstrate that object detectors based on the YOLO family are promising for the construction of litter detection solutions, with superior performance in terms of detection accuracy, processing time, and memory footprint.},
  article-number = {548},
  doi            = {10.3390/s22020548},
  keywords       = {Marine litter monitoring, Citizen science, Mobile application, Machine learning, Litter detection, Geographic visualization, User study},
  publisher      = {MDPI AG},
  pubmedid       = {35062507},
  url            = {https://www.mdpi.com/1424-8220/22/2/548},
}

@Article{Breda2022SRNature,
  author    = {Breda, Fabio Leandro and Manchado-Gobatto, F{\'u}lvia Barros and de Barros Sousa, Filipe Ant{\^o}nio and Beck, Wladimir Rafael and Pinto, Allan and Papoti, Marcelo and Scariot, Pedro Paulo Menezes and Gobatto, Claudio Alexandre},
  title     = {Complex networks analysis reinforces centrality hematological role on aerobic--anaerobic performances of the Brazilian Paralympic endurance team after altitude training},
  journal   = {Scientific Reports},
  year      = {2022},
  volume    = {12},
  number    = {1},
  pages     = {1148},
  month     = jan,
  issn      = {2045-2322},
  abstract  = {This study investigated the 30-days altitude training (2500 m, LHTH-live and training high) on hematological responses and aerobic--anaerobic performances parameters of high-level Paralympic athletes. Aerobic capacity was assessed by 3000 m run, and anaerobic variables (velocity, force and mechanical power) by a maximal 30-s semi-tethered running test (AO30). These assessments were carried out at low altitude before (PRE) and after LHTH (5--6 and 15--16 days, POST1 and POST2, respectively). During LHTH, hematological analyzes were performed on days 1, 12, 20 and 30. After LHTH, aerobic performance decreased 1.7{\%} in POST1, but showed an amazing increase in POST2 (15.4 s reduction in the 3000 m test, 2.8{\%}). Regarding anaerobic parameters, athletes showed a reduction in velocity, force and power in POST1, but velocity and power returned to their initial conditions in POST2. In addition, all participants had higher hemoglobin (Hb) values at the end of LHTH (30 days), but at POST2 these results were close to those of PRE. The centrality metrics obtained by complex networks (pondered degree, pagerank and betweenness) in the PRE and POST2 scenarios highlighted hemoglobin, hematocrit (Hct) and minimum force, velocity and power, suggesting these variables on the way to increasing endurance performance. The Jaccard's distance metrics showed dissimilarity between the PRE and POST2 graphs, and Hb and Hct as more prominent nodes for all centrality metrics. These results indicate that adaptive process from LHTH was highlighted by the complex networks, which can help understanding the better aerobic performance at low altitude after 16 days in Paralympic athletes.},
  day       = {21},
  doi       = {10.1038/s41598-022-04823-w},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Springer Science and Business Media LLC},
  url       = {https://doi.org/10.1038/s41598-022-04823-w},
}

@Article{Vieira2022IJERPH,
  author         = {Palucci Vieira, Luiz H. and Santiago, Paulo R. P. and Pinto, Allan and Aquino, Rodrigo and Torres, Ricardo da S. and Barbieri, Fabio A.},
  title          = {Automatic Markerless Motion Detector Method against Traditional Digitisation for 3-Dimensional Movement Kinematic Analysis of Ball Kicking in Soccer Field Context},
  journal        = {International Journal of Environmental Research and Public Health},
  year           = {2022},
  volume         = {19},
  number         = {3},
  pages          = {1179},
  month          = jan,
  issn           = {1660-4601},
  abstract       = {Kicking is a fundamental skill in soccer that often contributes to match outcomes. Lower limb movement features (e.g., joint position and velocity) are determinants of kick performance. However, obtaining kicking kinematics under field conditions generally requires time-consuming manual tracking. The current study aimed to compare a contemporary markerless automatic motion estimation algorithm (OpenPose) with manual digitisation (DVIDEOW software) in obtaining on-field kicking kinematic parameters. An experimental dataset of under-17 players from all outfield positions was used. Kick attempts were performed in an official pitch against a goalkeeper. Four digital video cameras were used to record full-body motion during support and ball contact phases of each kick. Three-dimensional positions of hip, knee, ankle, toe and foot centre-of-mass (CMfoot) generally showed no significant differences when computed by automatic as compared to manual tracking (whole kicking movement cycle), while only z-coordinates of knee and calcaneus markers at specific points differed between methods. The resulting time-series matrices of positions (r2 = 0.94) and velocity signals (r2 = 0.68) were largely associated (all p &lt; 0.01). The mean absolute error of OpenPose motion tracking was 3.49 cm for determining positions (ranging from 2.78 cm (CMfoot) to 4.13 cm (dominant hip)) and 1.29 m/s for calculating joint velocity (0.95 m/s (knee) to 1.50 m/s (non-dominant hip)) as compared to reference measures by manual digitisation. Angular range-of-motion showed significant correlations between methods for the ankle (r = 0.59, p &lt; 0.01, large) and knee joint displacements (r = 0.84, p &lt; 0.001, very large) but not in the hip (r = 0.04, p = 0.85, unclear). Markerless motion tracking (OpenPose) can help to successfully obtain some lower limb position, velocity, and joint angular outputs during kicks performed in a naturally occurring environment.},
  article-number = {1179},
  doi            = {10.3390/ijerph19031179},
  keywords       = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher      = {MDPI AG},
  url            = {https://www.mdpi.com/1660-4601/19/3/1179},
}

@Article{Pinto2022SRW,
  author    = {Allan Pinto and Gabriel Borin and Bruno Carlos and Matheus L. Bernardi and Matheus F. Sarmento and Alan Z. Peixinho and Thiago V. Spina and Eduardo X. Miqueles},
  title     = {Annotat3D: A Modern Web Application for Interactive Segmentation of Volumetric Images at Sirius/LNLS},
  journal   = {Synchrotron Radiation News},
  year      = {2022},
  volume    = {35},
  number    = {4},
  pages     = {36-43},
  month     = jul,
  issn      = {1931-7344},
  abstract  = {Recent advances in machine learning and scientific visualization have revolutionized the industry with novel applications and services that deeply impacted human life mainly. However, state-of-the-art machine learning models, especially deep models, are highly dependent on reliable data alongside their respective annotations. Unfortunately, label annotation is a time-consuming and costly task, especially for applications that require manual annotation performed by experts with special skills and domain knowledge. In this scenario, methods that assist experts to perform annotations effectively have a major impact on deploying reliable machine learning models. This article proposes a modern web application, called Annotat3D, that implements an interactive segmentation workflow at the Sirius/LNLS facility, enabling experts to perform fast and accurate tomographic volume labeling in high-performance computing (HPC) environment. As a result, the proposed application greatly impacts the workflow of both experts and non-experts users of Sirius' beamlines, since most of the tools available for image analysis and visualization are not optimized to operate in HPC environments. Our methodology takes advantage of recent developments in network communication to efficiently exchange data load in main memory between two-node clusters and modern web-based frameworks that allow us to build an efficient, clean, and simple graphical user interface.},
  doi       = {10.1080/08940886.2022.2112501},
  eprint    = {https://doi.org/10.1080/08940886.2022.2112501},
  keywords  = {Annotation Tools, High-performance computing, Machine Learning, Scientific Visualization, Deep Learning, Synchrotron, Synchrotron Radiation Application, X-ray Computed Tomography},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/08940886.2022.2112501},
}

@Article{Bini2022RQES,
  author    = {Rodrigo Rico Bini and Gil Serrancoli and Paulo Roberto Pereira Santiago and Allan Pinto and Felipe Moura},
  title     = {Validity of Neural Networks to Determine Body Position on the Bicycle},
  journal   = {Research Quarterly for Exercise and Sport},
  year      = {2022},
  volume    = {0},
  number    = {0},
  pages     = {1-8},
  month     = may,
  issn      = {2168-3824},
  note      = {PMID: 35575754},
  abstract  = { ABSTRACTPurpose: With the increased access to neural networks trained to estimate body segments from images and videos, this study assessed the validity of some of these networks in enabling the assessment of body position on the bicycle. Methods: Fourteen cyclists pedaled stationarily in one session on their own bicycles while video was recorded from their sagittal plane. Reflective markers attached to key bony landmarks were used to manually digitize joint angles at two positions of the crank (3 o’clock and 6 o’clock) extracted from the videos (Reference method). These angles were compared to measurements taken from videos generated by two deep learning-based approaches designed to automatically estimate human joints (Microsoft Research Asia-MSRA and OpenPose). Results: Mean bias for OpenPose ranged between 0.03° and 1.81°, while the MSRA method presented errors between 2.29° and 12.15°. Correlation coefficients were stronger for OpenPose than for the MSRA method in relation to the Reference method for the torso (r = 0.94 vs. 0.92), hip (r = 0.69 vs. 0.60), knee (r = 0.80 vs. 0.71), and ankle (r = 0.23 vs. 0.20). Conclusion: OpenPose presented better accuracy than the MSRA method in determining body position on the bicycle, but both methods seem comparable in assessing implications from changes in bicycle configuration. },
  doi       = {10.1080/02701367.2022.2070103},
  eprint    = {https://doi.org/10.1080/02701367.2022.2070103},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Routledge},
  url       = {https://doi.org/10.1080/02701367.2022.2070103},
}

@Article{ManchadoGobatto2022Biology,
  author         = {Manchado-Gobatto, Fúlvia Barros and Torres, Ricardo Silva and Marostegan, Anita Brum and Rasteiro, Felipe Marroni and Hartz, Charlini Simoni and Moreno, Marlene Aparecida and Pinto, Allan Silva and Gobatto, Claudio Alexandre},
  title          = {Complex Network Model Reveals the Impact of Inspiratory Muscle Pre-Activation on Interactions among Physiological Responses and Muscle Oxygenation during Running and Passive Recovery},
  journal        = {Biology},
  year           = {2022},
  volume         = {11},
  number         = {7},
  pages          = {963},
  month          = jun,
  issn           = {2079-7737},
  abstract       = {Although several studies have focused on the adaptations provided by inspiratory muscle (IM) training on physical demands, the warm-up or pre-activation (PA) of these muscles alone appears to generate positive effects on physiological responses and performance. This study aimed to understand the effects of inspiratory muscle pre-activation (IMPA) on high-intensity running and passive recovery, as applied to active subjects. In an original and innovative investigation of the impacts of IMPA on high-intensity running, we proposed the identification of the interactions among physical characteristics, physiological responses and muscle oxygenation in more and less active muscle to a running exercise using a complex network model. For this, fifteen male subjects were submitted to all-out 30 s tethered running efforts preceded or not preceded by IMPA, composed of 2 &times; 15 repetitions (1 min interval between them) at 40% of the maximum individual inspiratory pressure using a respiratory exercise device. During running and recovery, we monitored the physiological responses (heart rate, blood lactate, oxygen saturation) and muscle oxygenation (in vastus lateralis and biceps brachii) by wearable near-infrared spectroscopy (NIRS). Thus, we investigated four scenarios: two in the tethered running exercise (with or without IMPA) and two built into the recovery process (after the all-out 30 s), under the same conditions. Undirected weighted graphs were constructed, and four centrality metrics were analyzed (Degree, Betweenness, Eigenvector, and Pagerank). The IMPA (40% of the maximum inspiratory pressure) was effective in increasing the peak and mean relative running power, and the analysis of the complex networks advanced the interpretation of the effects of physiological adjustments related to the IMPA on exercise and recovery. Centrality metrics highlighted the nodes related to muscle oxygenation responses (in more and less active muscles) as significant to all scenarios, and systemic physiological responses mediated this impact, especially after IMPA application. Our results suggest that this respiratory strategy enhances exercise, recovery and the multidimensional approach to understanding the effects of physiological adjustments on these conditions.},
  article-number = {963},
  doi            = {10.3390/biology11070963},
  keywords       = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher      = {MDPI AG},
  pubmedid       = {36101345},
  url            = {https://www.mdpi.com/2079-7737/11/7/963},
}

@Article{Claro2023APR,
  author    = {Claro, Pedro I. C. and Borges, Egon P. B. S. and Schleder, Gabriel R. and Archilha, Nathaly L. and Pinto, Allan and Carvalho, Murilo and Driemeier, Carlos E. and Fazzio, Adalberto and Gouveia, Rubia F.},
  title     = {{From micro- to nano- and time-resolved x-ray computed tomography: Bio-based applications, synchrotron, synchrotron capabilities, and data-driven processing}},
  journal   = {Applied Physics Reviews},
  year      = {2023},
  volume    = {10},
  number    = {2},
  month     = apr,
  issn      = {1931-9401},
  note      = {021302},
  abstract  = {{X-ray computed microtomography (μCT) is an innovative and nondestructive versatile technique that has been used extensively to investigate bio-based systems in multiple application areas. Emerging progress in this field has brought countless studies using μCT characterization, revealing three-dimensional (3D) material structures and quantifying features such as defects, pores, secondary phases, filler dispersions, and internal interfaces. Recently, x-ray computed tomography (CT) beamlines coupled to synchrotron light sources have also enabled computed nanotomography (nCT) and four-dimensional (4D) characterization, allowing in situ, in vivo, and in operando characterization from the micro- to nanostructure. This increase in temporal and spatial resolutions produces a deluge of data to be processed, including real-time processing, to provide feedback during experiments. To overcome this issue, deep learning techniques have risen as a powerful tool that permits the automation of large amounts of data processing, availing the maximum beamline capabilities. In this context, this review outlines applications, synchrotron capabilities, and data-driven processing, focusing on the urgency of combining computational tools with experimental data. We bring a recent overview on this topic to researchers and professionals working not only in this and related areas but also to readers starting their contact with x-ray CT techniques and deep learning.}},
  doi       = {10.1063/5.0129324},
  eprint    = {https://pubs.aip.org/aip/apr/article-pdf/doi/10.1063/5.0129324/16822301/021302\_1\_5.0129324.pdf},
  publisher = {AIP Publishing},
  keywords  = {Data processing, Machine learning, Aerogel, Porous media, Biomaterials, Computational methods, Synchrotron, Synchrotron Radiation Application, X-ray Computed Tomography, X-ray Computed Microtomography, X-ray Computed Nanotomography, Time-resolved X-ray Computed Tomography},
  url       = {https://doi.org/10.1063/5.0129324},
}

@Article{Frade2023PlosOne,
  author    = {Frade, Maria Cecília Moraes and Beltrame, Thomas and Gois, Mariana de Oliveira and Pinto, Allan and Tonello, Silvia Cristina Garcia de Moura and Torres, Ricardo da Silva and Catai, Aparecida Maria},
  title     = {Toward characterizing cardiovascular fitness using machine learning based on unobtrusive data},
  journal   = {PLOS ONE},
  year      = {2023},
  volume    = {18},
  number    = {3},
  pages     = {1-18},
  month     = {03},
  issn      = {1932-6203},
  abstract  = {Cardiopulmonary exercise testing (CPET) is a non-invasive approach to measure the maximum oxygen uptake (V˙O2−max), which is an index to assess cardiovascular fitness (CF). However, CPET is not available to all populations and cannot be obtained continuously. Thus, wearable sensors are associated with machine learning (ML) algorithms to investigate CF. Therefore, this study aimed to predict CF by using ML algorithms using data obtained by wearable technologies. For this purpose, 43 volunteers with different levels of aerobic power, who wore a wearable device to collect unobtrusive data for 7 days, were evaluated by CPET. Eleven inputs (sex, age, weight, height, and body mass index, breathing rate, minute ventilation, total hip acceleration, walking cadence, heart rate, and tidal volume) were used to predict the V˙O2−max by support vector regression (SVR). Afterward, the SHapley Additive exPlanations (SHAP) method was used to explain their results. SVR was able to predict the CF, and the SHAP method showed that the inputs related to hemodynamic and anthropometric domains were the most important ones to predict the CF. Therefore, we conclude that the cardiovascular fitness can be predicted by wearable technologies associated with machine learning during unsupervised activities of daily living.},
  doi       = {10.1371/journal.pone.0282398},
  editor    = {Jaafar, Zulkarnain},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0282398},
}

@Article{Bini2023JSC,
  author    = {Rodrigo Rico Bini and Gil Serrancoli and Paulo Roberto Pereira Santiago and Allan Pinto and Felipe Moura},
  title     = {Criterion validity of neural networks to assess lower limb motion during cycling},
  journal   = {Journal of Sports Sciences},
  year      = {2023},
  volume    = {41},
  number    = {1},
  pages     = {36-44},
  month     = jan,
  issn      = {1466-447X},
  note      = {PMID: 36975046},
  abstract  = {The use of marker-less methods to automatically obtain kinematics of movement is expanding but validity to high-velocity tasks such as cycling with the presence of the bicycle on the field of view is needed when standard video footage is obtained. The purpose of this study was to assess if pre-trained neural networks are valid for calculations of lower limb joint kinematics during cycling. Motion of twenty-six cyclists pedalling on a cycle trainer was captured by a video camera capturing frames from the sagittal plane whilst reflective markers were attached to their lower limb. The marker-tracking method was compared to two established deep learning-based approaches (Microsoft Research Asia-MSRA and OpenPose) to estimate hip, knee and ankle joint angles. Poor to moderate agreement was found for both methods, with OpenPose differing from the criterion by 4–8° for the hip and knee joints. Larger errors were observed for the ankle joint (15–22°) but no significant differences between methods throughout the crank cycle when assessed using Statistical Parametric Mapping were observed for any of the joints. OpenPose presented stronger agreement with marker-tracking (criterion) than the MSRA for the hip and knee joints but resulted in poor agreement for the ankle joint. },
  doi       = {10.1080/02640414.2023.2194725},
  eprint    = {https://doi.org/10.1080/02640414.2023.2194725},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Routledge},
  url       = {https://doi.org/10.1080/02640414.2023.2194725},
}

@Article{Stival2023PlosOne,
  author    = {Stival, Leandro and Pinto, Allan and Andrade, Felipe dos Santos Pinto de and Santiago, Paulo Roberto Pereira and Biermann, Henrik and Torres, Ricardo da Silva and Dias, Ulisses},
  title     = {Using machine learning pipeline to predict entry into the attack zone in football},
  journal   = {PLOS ONE},
  year      = {2023},
  volume    = {18},
  number    = {1},
  pages     = {1-24},
  month     = {01},
  issn      = {1932-6203},
  abstract  = {Sports sciences are increasingly data-intensive nowadays since computational tools can extract information from large amounts of data and derive insights from athlete performances during the competition. This paper addresses a performance prediction problem in soccer, a popular collective sport modality played by two teams competing against each other in the same field. In a soccer game, teams score points by placing the ball into the opponent’s goal and the winner is the team with the highest count of goals. Retaining possession of the ball is one key to success, but it is not enough since a team needs to score to achieve victory, which requires an offensive toward the opponent’s goal. The focus of this work is to determine if analyzing the first five seconds after the control of the ball is taken by one of the teams provides enough information to determine whether the ball will reach the final quarter of the soccer field, therefore creating a goal-scoring chance. By doing so, we can further investigate which conditions increase strategic leverage. Our approach comprises modeling players’ interactions as graph structures and extracting metrics from these structures. These metrics, when combined, form time series that we encode in two-dimensional representations of visual rhythms, allowing feature extraction through deep convolutional networks, coupled with a classifier to predict the outcome (whether the final quarter of the field is reached). The results indicate that offensive play near the adversary penalty area can be predicted by looking at the first five seconds. Finally, the explainability of our models reveals the main metrics along with its contributions for the final inference result, which corroborates other studies found in the literature for soccer match analysis.},
  doi       = {10.1371/journal.pone.0265372},
  editor    = {Le, Nguyen Quoc Khanh},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0265372},
}

@Article{Merlin2022SMF,
  author    = {Murilo Merlin and Allan Pinto and Alexandre Gomes de Almeida and Felipe A Moura and Ricardo Da Silva Torres and Sergio Augusto Cunha},
  title     = {Classification and determinants of passing difficulty in soccer: a multivariate approach},
  journal   = {Science and Medicine in Football},
  year      = {2022},
  volume    = {6},
  number    = {4},
  pages     = {483-493},
  month     = oct,
  issn      = {2473-4446},
  note      = {PMID: 36412184},
  abstract  = {Introduction Usually, the players’ or teams’ efficiency to perform passes is measured in terms of accuracy. The degree of difficulty of this action has been overlooked in the literature.Objectives The present study aimed to classify the degree of passing difficulty in soccer matches and to identify and to discuss the variables that most explain the passing difficulty using spatiotemporal data.Results The data used corresponds to 2,856 passes and 32 independent variables. The Fisher Discriminant Analysis presented 72.0\% of the original grouped cases classified correctly. The passes analyzed were classified as low (56.5\%), medium (22.6\%), and high difficulty (20.9\%), and we identified 16 variables that best explain the degree of passing difficulty related to the passing receiver, ball trajectory, pitch position and passing player.Conclusions The merit and ability of the player to perform passes with high difficulty should be valued and can be used to rank the best players and teams.In addition, the highlighted variables should be looked carefully by coaches when analyzing profiles, strengths and weaknesses of players and teams, and talent identification context.Practical Implications The values found for each variable can be used as a reference for planning training, such as small side games, and in future research.},
  doi       = {10.1080/24733938.2021.1986227},
  eprint    = {https://doi.org/10.1080/24733938.2021.1986227},
  keywords  = {Machine Learning, Artificial Intelligence, Data Science, Sports Science},
  publisher = {Routledge},
  url       = {https://doi.org/10.1080/24733938.2021.1986227},
}

@Article{Wu2023EMS,
  author    = {Di Wu and Jincheng Liu and Manuel Cordova and Christina Carrozzo Hellevik and Jakob Bonnevie Cyvin and Allan Pinto and Ibrahim A. Hameed and Helio Pedrini and Ricardo {da Silva Torres} and Annik Magerholm Fet},
  title     = {The PlastOPol system for marine litter monitoring by citizen scientists},
  journal   = {Environmental Modelling \& Software},
  year      = {2023},
  volume    = {169},
  pages     = {105784},
  month     = nov,
  issn      = {1364-8152},
  abstract  = {Marine plastic pollution has in recent decades become ubiquitous, posing threats to flora, fauna, and potentially human health. Proper monitoring and registration of litter occurrences are, therefore, of paramount importance to support better-informed decision-making. In this paper, we introduce the PlastOPol marine litter monitoring system. PlastOPol integrates external data sources on beached litter with data collected through citizen science initiatives based on the use of a mobile application (App). The App relies on state-of-the-art machine-learning approaches for litter detection and registration. The system also supports a human-in-the-loop strategy based on which improved versions of litter detection models are created over time thanks to annotations by citizen scientists. Finally, the system includes a geographic visualization tool to support the analysis of litter distribution data by decision-makers. This system has the potential to create a direct path between citizens, researchers, and decision-makers on the issue of marine litter. Finally, the paper presents compelling usage scenarios of the proposed monitoring system and discusses the evaluation of the App through a user study. The user study suggests that the PlastOPol system is an effective and valuable tool to monitor and communicate marine litter.},
  doi       = {https://doi.org/10.1016/j.envsoft.2023.105784},
  keywords  = {Marine litter monitoring, Citizen science, Mobile application, Machine learning, Litter detection, Geographic visualization, User study},
  publisher = {Elsevier BV},
  url       = {https://www.sciencedirect.com/science/article/pii/S1364815223001706},
}

@inproceedings{Goetz2023ICALEPCS,
  author       = {A. Götz and M. AlMohammad and P. Austin and M. Bodin and V. Bozhinov and R. Cabezas Quirós and L.E. Davies and A. De Maria Antolinos and M. Gaonach and A. Gonzalez Beltran and R. Krahl and S.A. Matalgah and K.S. Phipps and A. Pinto and K. Syder},
  title        = {{Extending the ICAT Metadata Catalogue to New Scientific Use Cases}},
  booktitle    = {Proc. 19th Int. Conf. Accel. Large Exp. Phys. Control Syst. (ICALEPCS'23)},
  eventdate    = {2023-10-09/2023-10-13},
  pages        = {1033--1040},
  paper        = {WE3BCO07},
  language     = {english},
  keywords     = {Synchrotron, Data Management, Metadata, Data Catalog, ICAT, NeXus},
  venue        = {Cape Town, South Africa},
  series       = {International Conference on Accelerator and Large Experimental Physics Control Systems},
  number       = {19},
  publisher    = {JACoW Publishing, Geneva, Switzerland},
  month        = {02},
  year         = {2024},
  issn         = {2226-0358},
  isbn         = {978-3-95450-238-7},
  doi          = {10.18429/JACoW-ICALEPCS2023-WE3BCO07},
  url          = {https://jacow.org/icalepcs2023/papers/we3bco07.pdf},
  abstract     = {{The ICAT metadata catalogue is a flexible solution for managing scientific metadata and data from a wide variety of domains following the FAIR data principles. This paper will present an update of recent developments of the ICAT metadata catalogue and the latest status of the ICAT collaboration. ICAT was originally developed by UK Science and Technology Facilities Council (STFC) to manage the scientific data of ISIS Neutron and Muon Source and Diamond Light Source. They have since been joined by a number of other institutes including ESRF, HZB, SESAME, and ALBA who together now form the ICAT Collaboration. ICAT has been used to manage petabytes of scientific data for ISIS, DLS, ESRF, HZB, and in the future SESAME and ALBA and make these data FAIR. The latest version of the ICAT core as well as the new user interfaces, DataGateway and DataHub, and extensions to ICAT for implementing free text searching, a common search interface across Photon and Neutron catalogues, a protocol-based interface that allows making the metadata available for findability, electronic logbooks, sample tracking, and web-based data and domain specific viewers developed by the community will be presented. Finally recent developments to use ICAT to develop applications for processed data with rich metadata in the fields of small angle scattering, macromolecular crystallography and cryo-electron microscopy will be described. https://icatproject.org }},
}

@InProceedings{Mausbach2023ICALEPCS,
  author    = {P.B. Mausbach and E.X. Miqueles and A. Pinto},
  title     = {{Assonant: A Beamline-Agnostic Event Processing Engine for Data Collection and Standardization}},
  booktitle = {Proc. 19th Int. Conf. Accel. Large Exp. Phys. Control Syst. (ICALEPCS'23)},
  year      = {2024},
  number    = {19},
  series    = {International Conference on Accelerator and Large Experimental Physics Control Systems},
  pages     = {1025--1032},
  month     = {02},
  publisher = {JACoW Publishing, Geneva, Switzerland},
  abstract  = {{Synchrotron radiation facilities comprise beamlines designed to perform a wide range of X-ray experimental techniques which require complex instruments to monitor thermodynamic variables, sample-related variables, among others. Thus, synchrotron beamlines can produce heterogeneous sets of data and metadata, hereafter referred to as data, which impose several challenges to standardizing them. For open science and FAIR principles, such standardization is paramount for research reproducibility, besides accelerating the development of scalable and reusable data-driven solutions. To address this issue, the Assonant was devised to collect and standardize the data produced at beamlines of Sirius, the Brazilian fourth-generation synchrotron light source. This solution enables a NeXus-compliant technique-centric data standard at Sirius transparently for beamline teams by removing the burden of standardization tasks from them and providing a unified standardization solution for several techniques at Sirius. The Assonant implements a software interface to abstract data format-related specificities and to send the produced data to an event-driven infrastructure composed of streaming processing and microservices, able to transform the data flow according to NeXus. This paper presents the development process of Assonant, the strategy adopted to standardize beamlines with different operating stages, and challenges faced during the standardization process for macromolecular crystallography and imaging data at Sirius.}},
  doi       = {10.18429/JACoW-ICALEPCS2023-WE3BCO06},
  eventdate = {2023-10-09/2023-10-13},
  isbn      = {978-3-95450-238-7},
  issn      = {2226-0358},
  keywords  = {Synchrotron, Data Management, NeXus, Data Standardization},
  language  = {english},
  paper     = {WE3BCO06},
  url       = {https://jacow.org/icalepcs2023/papers/we3bco06.pdf},
  venue     = {Cape Town, South Africa},
}

@Article{Caznok2024FN,
  author    = {Caznok Silveira, Ana Clara and Antunes, Andre Saraiva Leão Marcelo and Athié, Maria Carolina Pedro and da Silva, Bárbara Filomena and Ribeiro dos Santos, João Victor and Canateli, Camila and Fontoura, Marina Alves and Pinto, Allan and Pimentel-Silva, Luciana Ramalho and Avansini, Simoni Helena and de Carvalho, Murilo},
  title     = {Between neurons and networks: investigating mesoscale brain connectivity in neurological and psychiatric disorders},
  journal   = {Frontiers in Neuroscience},
  year      = {2024},
  volume    = {18},
  month     = feb,
  issn      = {1662-453X},
  abstract  = {The study of brain connectivity has been a cornerstone in understanding the complexities of neurological and psychiatric disorders. It has provided invaluable insights into the functional architecture of the brain and how it is perturbed in disorders. However, a persistent challenge has been achieving the proper spatial resolution, and developing computational algorithms to address biological questions at the multi-cellular level, a scale often referred to as the mesoscale. Historically, neuroimaging studies of brain connectivity have predominantly focused on the macroscale, providing insights into inter-regional brain connections but often falling short of resolving the intricacies of neural circuitry at the cellular or mesoscale level. This limitation has hindered our ability to fully comprehend the underlying mechanisms of neurological and psychiatric disorders and to develop targeted interventions. In light of this issue, our review manuscript seeks to bridge this critical gap by delving into the domain of mesoscale neuroimaging. We aim to provide a comprehensive overview of conditions affected by aberrant neural connections, image acquisition techniques, feature extraction, and data analysis methods that are specifically tailored to the mesoscale. We further delineate the potential of brain connectivity research to elucidate complex biological questions, with a particular focus on schizophrenia and epilepsy. This review encompasses topics such as dendritic spine quantification, single neuron morphology, and brain region connectivity. We aim to showcase the applicability and significance of mesoscale neuroimaging techniques in the field of neuroscience, highlighting their potential for gaining insights into the complexities of neurological and psychiatric disorders.},
  doi       = {10.3389/fnins.2024.1340345},
  keywords  = {Synchrotron, Synchrotron Radiation Application, Artificial Intelligence, Machine Learning, Brain connectivity, Bioimaging},
  publisher = {Frontiers Media SA},
  url       = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1340345},
}

@Article{Merlin2024PlosOne,
  author    = {Merlin, Murilo and Pinto, Allan and Moura, Felipe Arruda and Torres, Ricardo da Silva and Cunha, Sergio Augusto},
  title     = {Who are the best passing players in professional soccer? A machine learning approach for classifying passes with different levels of difficulty and discriminating the best passing players},
  journal   = {PLOS ONE},
  year      = {2024},
  volume    = {19},
  number    = {5},
  pages     = {1-16},
  month     = {05},
  issn      = {1932-6203},
  abstract  = {The present study aimed to assess the use of technical-tactical variables and machine learning (ML) classifiers in the automatic classification of the passing difficulty (DP) level in soccer matches and to illustrate the use of the model with the best performance to distinguish the best passing players. We compared eight ML classifiers according to their accuracy performance in classifying passing events using 35 technical-tactical variables based on spatiotemporal data. The Support Vector Machine (SVM) algorithm achieved a balanced accuracy of 0.70 ± 0.04%, considering a multi-class classification. Next, we illustrate the use of the best-performing classifier in the assessment of players. In our study, 2,522 pass actions were classified by the SVM algorithm as low (53.9%), medium (23.6%), and high difficulty passes (22.5%). Furthermore, we used successful rates in low-DP, medium-DP, and high-DP as inputs for principal component analysis (PCA). The first principal component (PC1) showed a higher correlation with high-DP (0.80), followed by medium-DP (0.73), and low-DP accuracy (0.24). The PC1 scores were used to rank the best passing players. This information can be a very rich performance indication by ranking the best passing players and teams and can be applied in offensive sequences analysis and talent identification.},
  doi       = {10.1371/journal.pone.0304139},
  editor    = {Muazu Musa, Rabiu},
  keywords  = {Artificial Intelligence, Machine Learning, Data Science},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0304139},
}

@InProceedings{Pinto2024SBAC,
  author    = {Pinto, Allan and Leite, Gustavo and Pereira, Marcio and Yviquel, Herve and Rigo, Sandro and Araujo, Guido},
  title     = {{ DeepWave: A Software Stack for Parallelizing Deep Learning Models Used in Geophysics }},
  booktitle = {2024 IEEE 36th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  year      = {2024},
  pages     = {49-58},
  address   = {Los Alamitos, CA, USA},
  month     = Nov,
  publisher = {IEEE Computer Society},
  abstract  = { This paper introduces DeepWave, a novel software stack, and methodology designed to integrate generative artificial intelligence into traditional seismic surveying techniques, significantly enhancing the computational efficiency of geophysical exploration. By utilizing advanced machine learning frameworks such as JAX, FLAX, and ALPA, DeepWave employs a parallelization strategy for image-to-image translation networks, optimizing the seismic data interpretation process. DeepWave reduces the computational demands of intensive geophysical algorithms, such as Full-waveform Inversion (FWI), while maintaining the accuracy required for detailed subsurface analysis. This method enables faster and more efficient processing of large seismic datasets, providing deeper insights into the Earth’s subsurface structures with reduced computational resources. The results demonstrate a substantial improvement in processing speed and resource management, establishing a new geophysical research and exploration standard. },
  doi       = {10.1109/SBAC-PAD63648.2024.00013},
  keywords  = {Training;Deep learning;Machine learning algorithms;Computational modeling;High performance computing;Full stack;Parallel processing;Computational efficiency;Resource management;Standards},
  url       = {https://doi.ieeecomputersociety.org/10.1109/SBAC-PAD63648.2024.00013},
}

@Comment{jabref-meta: databaseType:bibtex;}
